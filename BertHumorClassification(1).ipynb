{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BertHumorClassification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "82e27432fbb14f649946ecd8386a3c50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f4581629514947ce98c78ea8d5b278ca",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d88e563bce5343a4bfe553c4edf9b550",
              "IPY_MODEL_303580dc4c4846a3aff6f205fad7d0e7"
            ]
          }
        },
        "f4581629514947ce98c78ea8d5b278ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d88e563bce5343a4bfe553c4edf9b550": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b3a9c5f5ec644398b52521ce59a84c37",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 213450,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 213450,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e1a6f3b0864e4b3db67cc3b68a2aa94e"
          }
        },
        "303580dc4c4846a3aff6f205fad7d0e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5974960d13424621b0563f9a098065db",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 213k/213k [00:03&lt;00:00, 58.8kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_faf35afb7adc4df5b784b293731118d7"
          }
        },
        "b3a9c5f5ec644398b52521ce59a84c37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e1a6f3b0864e4b3db67cc3b68a2aa94e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5974960d13424621b0563f9a098065db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "faf35afb7adc4df5b784b293731118d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c8fd398bb0f147e68ce79ca6f9987b1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0181c89d812b4b6aa95d7fe2ef22ba9c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5d73ddb300604959b0526b7adb47e176",
              "IPY_MODEL_8026111ae512457aa3a7d663424b5711"
            ]
          }
        },
        "0181c89d812b4b6aa95d7fe2ef22ba9c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5d73ddb300604959b0526b7adb47e176": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0eac4e5259d04a6eb4c430130498b35a",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 29,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 29,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_18463760a8ac47c3b55e5f437ca29e1d"
          }
        },
        "8026111ae512457aa3a7d663424b5711": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a9504ca4e1784f86b1d2282d961ad024",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 29.0/29.0 [00:01&lt;00:00, 15.5B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0346fc00b15b4ebeb9dab416f0ee67a7"
          }
        },
        "0eac4e5259d04a6eb4c430130498b35a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "18463760a8ac47c3b55e5f437ca29e1d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a9504ca4e1784f86b1d2282d961ad024": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0346fc00b15b4ebeb9dab416f0ee67a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e7ca593edd1b4d23ac875b912a6e38cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8269262e3c7b4a8687c1900e218fe827",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_65d82e116fc04ee6b35c0e3c0283f497",
              "IPY_MODEL_1e509a1e590047689246540bee1fa049"
            ]
          }
        },
        "8269262e3c7b4a8687c1900e218fe827": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "65d82e116fc04ee6b35c0e3c0283f497": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_aa27beb689b54ebcb19f25b631d7a29d",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 435797,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 435797,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1cc7cf61263b4936b2e1abfe2b1f9af4"
          }
        },
        "1e509a1e590047689246540bee1fa049": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_76d1c539b0954a088ec958d4d20a122a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 436k/436k [00:00&lt;00:00, 1.09MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f5f405a5c2da4695aca22c12f5551bff"
          }
        },
        "aa27beb689b54ebcb19f25b631d7a29d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1cc7cf61263b4936b2e1abfe2b1f9af4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "76d1c539b0954a088ec958d4d20a122a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f5f405a5c2da4695aca22c12f5551bff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f6c2a58c9dab4cc692b67d30174ba344": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_7b0adbeecabb43539b3db148d8207fd4",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_81d7c56bac0a4ce4ad249e68e7d591c7",
              "IPY_MODEL_16fd439295684b5ab8e4631e673a8b59"
            ]
          }
        },
        "7b0adbeecabb43539b3db148d8207fd4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "81d7c56bac0a4ce4ad249e68e7d591c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_fc4d19e99f584adcb3e7d73c407a33a6",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 570,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 570,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_18c9a355f7c840c6bf0316effc5254d4"
          }
        },
        "16fd439295684b5ab8e4631e673a8b59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_fd8b70d281c5471fa2cf38bb33f4f4b3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 570/570 [00:00&lt;00:00, 11.9kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e7c983d515554b57bd42b2c00a919664"
          }
        },
        "fc4d19e99f584adcb3e7d73c407a33a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "18c9a355f7c840c6bf0316effc5254d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fd8b70d281c5471fa2cf38bb33f4f4b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e7c983d515554b57bd42b2c00a919664": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "36570ecb94e540d0a4494bdbaac6447f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_69df13e118f14807a425dd5fa843f389",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_27c27409d3ce43e697c0a1d38ec2a09c",
              "IPY_MODEL_290fdda386104df2b4a6ce0aecea31bb"
            ]
          }
        },
        "69df13e118f14807a425dd5fa843f389": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "27c27409d3ce43e697c0a1d38ec2a09c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b22ca5d1c0384b13b1d44dc5108c2bf6",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 435779157,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 435779157,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_60f6b260199546dca4dcbad5ffb1d682"
          }
        },
        "290fdda386104df2b4a6ce0aecea31bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_cf54e57017dd434d81a2600e2d2e639b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 436M/436M [00:13&lt;00:00, 32.3MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5a9b245496824420b5c18b0355ae46f6"
          }
        },
        "b22ca5d1c0384b13b1d44dc5108c2bf6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "60f6b260199546dca4dcbad5ffb1d682": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cf54e57017dd434d81a2600e2d2e639b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5a9b245496824420b5c18b0355ae46f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "BSE8Wq6nxNf7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "743cec47-6d8d-44a3-94d2-bef3b9ce98b2"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d5/43/cfe4ee779bbd6a678ac6a97c5a5cdeb03c35f9eaebbb9720b036680f9a2d/transformers-4.6.1-py3-none-any.whl (2.2MB)\n",
            "\r\u001b[K     |▏                               | 10kB 12.8MB/s eta 0:00:01\r\u001b[K     |▎                               | 20kB 16.9MB/s eta 0:00:01\r\u001b[K     |▍                               | 30kB 20.6MB/s eta 0:00:01\r\u001b[K     |▋                               | 40kB 23.8MB/s eta 0:00:01\r\u001b[K     |▊                               | 51kB 26.4MB/s eta 0:00:01\r\u001b[K     |▉                               | 61kB 27.7MB/s eta 0:00:01\r\u001b[K     |█                               | 71kB 28.9MB/s eta 0:00:01\r\u001b[K     |█▏                              | 81kB 29.3MB/s eta 0:00:01\r\u001b[K     |█▎                              | 92kB 24.7MB/s eta 0:00:01\r\u001b[K     |█▌                              | 102kB 25.2MB/s eta 0:00:01\r\u001b[K     |█▋                              | 112kB 25.2MB/s eta 0:00:01\r\u001b[K     |█▊                              | 122kB 25.2MB/s eta 0:00:01\r\u001b[K     |██                              | 133kB 25.2MB/s eta 0:00:01\r\u001b[K     |██                              | 143kB 25.2MB/s eta 0:00:01\r\u001b[K     |██▏                             | 153kB 25.2MB/s eta 0:00:01\r\u001b[K     |██▎                             | 163kB 25.2MB/s eta 0:00:01\r\u001b[K     |██▌                             | 174kB 25.2MB/s eta 0:00:01\r\u001b[K     |██▋                             | 184kB 25.2MB/s eta 0:00:01\r\u001b[K     |██▊                             | 194kB 25.2MB/s eta 0:00:01\r\u001b[K     |███                             | 204kB 25.2MB/s eta 0:00:01\r\u001b[K     |███                             | 215kB 25.2MB/s eta 0:00:01\r\u001b[K     |███▏                            | 225kB 25.2MB/s eta 0:00:01\r\u001b[K     |███▍                            | 235kB 25.2MB/s eta 0:00:01\r\u001b[K     |███▌                            | 245kB 25.2MB/s eta 0:00:01\r\u001b[K     |███▋                            | 256kB 25.2MB/s eta 0:00:01\r\u001b[K     |███▉                            | 266kB 25.2MB/s eta 0:00:01\r\u001b[K     |████                            | 276kB 25.2MB/s eta 0:00:01\r\u001b[K     |████                            | 286kB 25.2MB/s eta 0:00:01\r\u001b[K     |████▎                           | 296kB 25.2MB/s eta 0:00:01\r\u001b[K     |████▍                           | 307kB 25.2MB/s eta 0:00:01\r\u001b[K     |████▌                           | 317kB 25.2MB/s eta 0:00:01\r\u001b[K     |████▋                           | 327kB 25.2MB/s eta 0:00:01\r\u001b[K     |████▉                           | 337kB 25.2MB/s eta 0:00:01\r\u001b[K     |█████                           | 348kB 25.2MB/s eta 0:00:01\r\u001b[K     |█████                           | 358kB 25.2MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 368kB 25.2MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 378kB 25.2MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 389kB 25.2MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 399kB 25.2MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 409kB 25.2MB/s eta 0:00:01\r\u001b[K     |██████                          | 419kB 25.2MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 430kB 25.2MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 440kB 25.2MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 450kB 25.2MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 460kB 25.2MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 471kB 25.2MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 481kB 25.2MB/s eta 0:00:01\r\u001b[K     |███████                         | 491kB 25.2MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 501kB 25.2MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 512kB 25.2MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 522kB 25.2MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 532kB 25.2MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 542kB 25.2MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 552kB 25.2MB/s eta 0:00:01\r\u001b[K     |████████                        | 563kB 25.2MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 573kB 25.2MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 583kB 25.2MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 593kB 25.2MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 604kB 25.2MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 614kB 25.2MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 624kB 25.2MB/s eta 0:00:01\r\u001b[K     |█████████                       | 634kB 25.2MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 645kB 25.2MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 655kB 25.2MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 665kB 25.2MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 675kB 25.2MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 686kB 25.2MB/s eta 0:00:01\r\u001b[K     |██████████                      | 696kB 25.2MB/s eta 0:00:01\r\u001b[K     |██████████                      | 706kB 25.2MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 716kB 25.2MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 727kB 25.2MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 737kB 25.2MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 747kB 25.2MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 757kB 25.2MB/s eta 0:00:01\r\u001b[K     |███████████                     | 768kB 25.2MB/s eta 0:00:01\r\u001b[K     |███████████                     | 778kB 25.2MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 788kB 25.2MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 798kB 25.2MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 808kB 25.2MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 819kB 25.2MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 829kB 25.2MB/s eta 0:00:01\r\u001b[K     |████████████                    | 839kB 25.2MB/s eta 0:00:01\r\u001b[K     |████████████                    | 849kB 25.2MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 860kB 25.2MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 870kB 25.2MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 880kB 25.2MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 890kB 25.2MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 901kB 25.2MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 911kB 25.2MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 921kB 25.2MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 931kB 25.2MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 942kB 25.2MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 952kB 25.2MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 962kB 25.2MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 972kB 25.2MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 983kB 25.2MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 993kB 25.2MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 1.0MB 25.2MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 1.0MB 25.2MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 1.0MB 25.2MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 1.0MB 25.2MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 1.0MB 25.2MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 1.1MB 25.2MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 1.1MB 25.2MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 1.1MB 25.2MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 1.1MB 25.2MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 1.1MB 25.2MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 1.1MB 25.2MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 1.1MB 25.2MB/s eta 0:00:01\r\u001b[K     |████████████████                | 1.1MB 25.2MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 1.1MB 25.2MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 1.1MB 25.2MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 1.2MB 25.2MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 1.2MB 25.2MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 1.2MB 25.2MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 1.2MB 25.2MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 1.2MB 25.2MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 1.2MB 25.2MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 1.2MB 25.2MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 1.2MB 25.2MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 1.2MB 25.2MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 1.2MB 25.2MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 1.3MB 25.2MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 1.3MB 25.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 1.3MB 25.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 1.3MB 25.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 1.3MB 25.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 1.3MB 25.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 1.3MB 25.2MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 1.3MB 25.2MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 1.3MB 25.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 1.4MB 25.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 1.4MB 25.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 1.4MB 25.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 1.4MB 25.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 1.4MB 25.2MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 1.4MB 25.2MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 1.4MB 25.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 1.4MB 25.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 1.4MB 25.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 1.4MB 25.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 1.5MB 25.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 1.5MB 25.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 1.5MB 25.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 1.5MB 25.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 1.5MB 25.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 1.5MB 25.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 1.5MB 25.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 1.5MB 25.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 1.5MB 25.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.5MB 25.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 1.6MB 25.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 1.6MB 25.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 1.6MB 25.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 1.6MB 25.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 1.6MB 25.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 1.6MB 25.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.6MB 25.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 1.6MB 25.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 1.6MB 25.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 1.6MB 25.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 1.7MB 25.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 1.7MB 25.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 1.7MB 25.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.7MB 25.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 1.7MB 25.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 1.7MB 25.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 1.7MB 25.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 1.7MB 25.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 1.7MB 25.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.8MB 25.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.8MB 25.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 1.8MB 25.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 1.8MB 25.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 1.8MB 25.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 1.8MB 25.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 1.8MB 25.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.8MB 25.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.8MB 25.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 1.8MB 25.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 1.9MB 25.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 1.9MB 25.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 1.9MB 25.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 1.9MB 25.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.9MB 25.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.9MB 25.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 1.9MB 25.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 1.9MB 25.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.9MB 25.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 1.9MB 25.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 2.0MB 25.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 2.0MB 25.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 2.0MB 25.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 2.0MB 25.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 2.0MB 25.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 2.0MB 25.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 2.0MB 25.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 2.0MB 25.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 2.0MB 25.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 2.0MB 25.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 2.1MB 25.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 2.1MB 25.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 2.1MB 25.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 2.1MB 25.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 2.1MB 25.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 2.1MB 25.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 2.1MB 25.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 2.1MB 25.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 2.1MB 25.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 2.2MB 25.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 2.2MB 25.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 2.2MB 25.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 2.2MB 25.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 2.2MB 25.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 2.2MB 25.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 2.2MB 25.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 2.2MB 25.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 2.2MB 25.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 2.2MB 25.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 2.3MB 25.2MB/s \n",
            "\u001b[?25hCollecting huggingface-hub==0.0.8\n",
            "  Downloading https://files.pythonhosted.org/packages/a1/88/7b1e45720ecf59c6c6737ff332f41c955963090a18e72acbcbeac6b25e86/huggingface_hub-0.0.8-py3-none-any.whl\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/e2/df3543e8ffdab68f5acc73f613de9c2b155ac47f162e725dcac87c521c11/tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 32.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.0.1)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 31.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Installing collected packages: huggingface-hub, tokenizers, sacremoses, transformers\n",
            "Successfully installed huggingface-hub-0.0.8 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.6.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xwe0f4TqZOXA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6dd12cf9-a22f-46df-8fc1-5b9c89c5ab31"
      },
      "source": [
        "%matplotlib inline\n",
        "import tensorflow as tf\n",
        "import torch\n",
        "import os\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from transformers import BertTokenizer\n",
        "from torch.utils.data import TensorDataset, random_split\n",
        "import matplotlib.pyplot as plt\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import BertForSequenceClassification, AdamW, BertConfig, BertTokenizer\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "import time\n",
        "import datetime\n",
        "from sklearn.model_selection import train_test_split\n",
        "import random\n",
        "import re\n",
        "import matplotlib\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import BertModel, BertPreTrainedModel\n",
        "from transformers.modeling_outputs import SequenceClassifierOutput\n",
        "from torch import nn\n",
        "from torch.nn import BCEWithLogitsLoss\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_2jcJsQsS-m"
      },
      "source": [
        "def clean_text(text):\n",
        "  text = text.lower()\n",
        "  text = re.sub(r\"what's\", \"what is \", text)\n",
        "  text = re.sub(r\"\\'s\", \" \", text)\n",
        "  text = re.sub(r\"’\", \"'\", text)\n",
        "  text = re.sub(r\"\\'ve\", \" have \", text)\n",
        "  text = re.sub(r\"can't\", \"can not \", text)\n",
        "  text = re.sub(r\"haven't\", \"have not \", text)\n",
        "  text = re.sub(r\"don't\", \"do not \", text)\n",
        "  text = re.sub(r\"wouldn't\", \"would not \", text)\n",
        "  text = re.sub(r\"i'm\", \"i am \", text)\n",
        "  text = re.sub(r\"\\'re\", \" are \", text)\n",
        "  text = re.sub(r\"\\'d\", \" would \", text)\n",
        "  text = re.sub('2', 'two', text)\n",
        "  text = re.sub(r\"\\'ll\", \" will \", text)\n",
        "  text = re.sub(r\"\\'scuse\", \" excuse \", text)\n",
        "  text = re.sub(r'says, \"', 'says: \"', text)\n",
        "  text = re.sub(\"in'\", 'ing', text)\n",
        "  text = text.replace(\"\\n\", \"\")\n",
        "  text = text.replace(\"\\t\", \"\")\n",
        "  text = text.strip(' ')\n",
        "  return text\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 726
        },
        "id": "O8d9GEymG82A",
        "outputId": "94ac55f3-b056-4c6c-b0c8-c65c2e0941d7"
      },
      "source": [
        "df = pd.read_csv(\"https://docs.google.com/spreadsheets/d/e/2PACX-1vQfFx3TMpHYWKXAiExoDC4qFpYal1n_y8yLAfQTHpUOCVFw67uukmf5rFd60McXEM0L6-vilYw2UK_q/pub?gid=0&single=true&output=csv\")\n",
        "def prepare_df(df):\n",
        "  df = df.dropna()\n",
        "  df = df.drop_duplicates(['joke'])\n",
        "  df['joke'] = df['joke'].map(lambda joke : clean_text(joke))\n",
        "  df[\"lang_play_two\"] = df[\"lang_play\"]\n",
        "  #df[\"humor_type\"] = df[\"lang_play\"]\n",
        "  df.loc[df['lang_play'].str.contains('homonymy', regex=True), \"lang_play\"] = \"polysemy\"\n",
        "  df.loc[df['lang_play'].str.contains('homophorm', regex=True), \"lang_play\"] = \"homophony\"\n",
        "  df.loc[df['lang_play_two'].str.contains('metaphor|comparison|repeat|antropomorphism', regex=True), \"lang_play_two\"] = \"stylistic\"\n",
        "  df.loc[df['lang_play_two'].str.contains('another|taboo', regex=True), \"lang_play_two\"] = \"another\"\n",
        "  df.loc[df['lang_play_two'].str.contains('homo\\w*|polysemy|acronym|synonymy|composition|semantics|syntax|archaism', regex=True), \"humor_type\"] = \"lexico-phonetic\"\n",
        "  #df = df[df['lang_play'] != 'another'] для анализа узконаправленных типов языковой игры\n",
        "\n",
        "  ######Для анализа типа юмора\n",
        "  #df[\"humor_type\"] = df[\"lang_play\"]\n",
        "  #df.loc[df['humor_type'].str.contains('another|taboo', regex=True), \"humor_type\"] = \"referential\"\n",
        "  #df.loc[df['humor_type'].str.contains('homo\\w*|polysemy|acronym|synonymy|composition|semantics|syntax|archaism|metaphor|comparison|repeat|antropomorphism', regex=True), \"humor_type\"]\n",
        "  \n",
        "  ######Для аннализа синтаксической структуры юмора\n",
        "  #df[\"text_structure\"] = df[\"text_structure\"].replace('\\nquestion-answer', 'question-answer')\n",
        "  return df\n",
        "\n",
        "df = prepare_df(df)\n",
        "\n",
        "cat_types = df[\"lang_play\"].value_counts().to_dict()\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.bar(cat_types.keys(), cat_types.values(), color = ['#1cd3a2', '#ffff00', '#6600ff', \"#808080\",'#ff69b4','#e100a5','#a020f0', \n",
        "     '#87ceeb', '#bbfd30', '#bb425b', \n",
        "     '#bbade2', '#bbf20d',  '#bb248b'])\n",
        "\n",
        "plt.xticks(rotation= 'vertical')\n",
        "plt.title(\"Data Distribution\")\n",
        "plt.ylabel('count', fontsize=12)\n",
        "plt.xlabel('lang_play', fontsize=12)\n",
        "plt.show()\n",
        "\n",
        "#def prepare_df(df):\n",
        "print('Number of unique text_structure_labels: {}'.format(len(list(set(df[\"lang_play\"].to_list())))))\n",
        "print('Number of training sentences: {:,}\\n'.format(len(df.drop_duplicates(['joke']))))\n",
        "#print(label_dict)\n",
        "print(df[\"lang_play\"].value_counts())\n",
        "df = df.drop_duplicates(['joke'])\n",
        "df[\"lang_play_two\"] = df[\"lang_play\"]\n",
        "#df[\"lang_play_two\"] = df[\"lang_play_two\"].replace(label_dict)\n",
        "df[\"labels\"] = 1\n",
        "df = df.pivot(index='joke', columns='lang_play', values=\"labels\").reset_index()\n",
        "df = df.fillna(np.float64(0))\n",
        "print(df.columns)\n",
        "#df[\"stylistic\"] = [int(i) for i in df[\"stylistic\"]]\n",
        "#df[\"lexico-phonetic\"] = [int(i) for i in df[\"lexico-phonetic\"]]\n",
        "#for col in df.columns[1:]:\n",
        "#  df[col] = [np.float64(i) for i in df[col]]\n",
        "#print(type(df[\"taboo\"][0]))\n",
        "\n",
        "categories = [i for i in df.columns[1:]]\n",
        "uniq_class = [i for i in range(1, len(categories)+ 1)]\n",
        "label_dict = {i:k for i,k in zip(categories, uniq_class)}\n",
        "df.sample()\n",
        "df.head(10)\n",
        "print(label_dict)\n",
        "#df.to_csv(\"nw.csv\")\n",
        "#\n",
        "#return df, categories\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfcAAAGeCAYAAACJjki1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deZhsZXm2/fOCjRijgIQdooAyiPjhwPAi4msSxySCGk3iDEgQxahJiEaNeU0E0cQhcZ5RREBRiUZBo0kQwREHEBUciIgSQBBUQERQhvv7Y62S2r17767adPeqtfr8HUcfXbVqVdVN07uveob1PKkqJEnScGzUdQGSJGlxGe6SJA2M4S5J0sAY7pIkDYzhLknSwBjukiQNjOEuab2SfCLJQYv0Wr+X5Lyx+z9I8rDFeO329b6Z5EGL9XpSXxnuUkfaYLsuyTVJrkryhSR/kWSif5dJtk9SSVbdihoqybVJfp7kJ0lOTfKE8XOqat+qOnbC17rb+s6pqs9W1S4bWu+c93t3kpfNef17VtXpi/H6Up8Z7lK3HlVVdwDuCrwC+Dvg6GWuYbequj2wC/Bu4E1JDl/sN7k1H0IkTcdwl2ZAVV1dVScDTwAOSnIvgCSPSHJ2kp8luSjJEWNP+0z7/aq25X3/JDsl+VTbCv9xkvcm2WLCGn5cVccDzwT+PslvtTWcnuRp7e27Jfl0kqvb1/9Ae3xUy9fbWp6Q5EFJLk7yd0kuA44ZHZvz1vdN8q0kVyY5Jslt29f88ySfGz9x1DuQ5FBgf+AF7ft9tH381938STZN8rokP2y/Xpdk0/axUW1/m+TyJJcmOXiSn5PUB4a7NEOq6svAxcDvtYeuBZ4CbAE8Anhmkse0j/1++32Lqrp9VZ0BBHg5cGfg/wO2A46YsoyTgFXA3vM89lLgv4E7AtsCb2zrHtWyW1vLB9r7vwNsSdMzceg63m9/4I+AnYC7A/+wUIFVdRTwXuBV7fs9ap7TXgTsA+wO7Nb+94y/9u8AmwPbAIcAb05yx4XeW+oDw12aPT+kCUSq6vSqOqeqbq6qbwDvAx64ridW1flVdUpV/bKqrgBes77z1/EaNwA/HtUwxw00QX3nqrq+qj43zznjbgYOb+u5bh3nvKmqLqqqnwL/BDxpmnrXY3/gyKq6vP1ZvAQ4cOzxG9rHb6iqjwM/pxmakHrPcJdmzzbATwGS3C/JaUmuSHI18BfAVut6YpKtk7w/ySVJfga8Z33nr+M1NgFWj2qY4wU0vQNfbmemP3WBl7uiqq5f4JyLxm5fSNPrsBju3L7eul77J1V149j9XwC3X6T3ljpluEszJMl9acJ91CI+ATgZ2K6qNgfeRhOuAPNt6fjP7fF7V9VmwAFj50/q0cCNwJfnPlBVl1XV06vqzsAzgLcsMEN+km0ntxu7fReangtohiRuN3ogye9M+do/pOllmO+1pUEz3KUZkGSzJI8E3g+8p6rOaR+6A/DTqro+yd7Ak8eedgVNt/eOY8fuQNO9fHWSbYDnT1HDlkn2B94MvLKqfjLPOY9Lsm1790qagL25vf+jObVM6tlJtk2yJc04+Wi8/uvAPZPs3k6yO2LO8xZ6v/cB/5BkdZKtgBfT9GRIg2e4S936aJJraLqmX0QzRj4+a/tZwJHtOS8GThw9UFW/oBmj/nx7nfw+NOPKewJXA/8B/PsENXw9yc+B84GnAc+pqhev49z7Al9qzz8ZOKyqLmgfOwI4tq3l8RO878gJNJP0LgC+B7ys/e/7H+BI4JPAd7mlN2PkaGDX9v0+Ms/rvgw4E/gGcA7w1dFrS0OXqkl6zSRJUl/YcpckaWAMd0mSBsZwlyRpYAx3SZIGZjAbOWy11Va1/fbbd12GJEnL4qyzzvpxVa2e77HBhPv222/PmWee2XUZkiQtiyQXrusxu+UlSRoYw12SpIEx3CVJGhjDXZKkgTHcJUkaGMNdkqSBMdwlSRoYw12SpIEx3CVJGhjDXZKkgTHcJUkamMGsLb/Ytjv3+K5LWMtF9zqw6xIkST1gy12SpIEx3CVJGhjDXZKkgTHcJUkaGMNdkqSBMdwlSRoYw12SpIEx3CVJGhjDXZKkgTHcJUkaGMNdkqSBMdwlSRoYw12SpIEx3CVJGhjDXZKkgTHcJUkaGMNdkqSBMdwlSRoYw12SpIEx3CVJGhjDXZKkgTHcJUkaGMNdkqSBMdwlSRoYw12SpIEx3CVJGphlC/ckP0hyTpKvJTmzPbZlklOSfLf9fsf2eJK8Icn5Sb6RZM/lqlOSpL5b7pb7g6tq96raq73/QuDUqtoZOLW9D7AvsHP7dSjw1mWuU5Kk3uq6W/7RwLHt7WOBx4wdP64aXwS2SHKnLgqUJKlvljPcC/jvJGclObQ9tnVVXdrevgzYur29DXDR2HMvbo+tIcmhSc5McuYVV1yxVHVLktQrq5bxvX63qi5J8tvAKUm+M/5gVVWSmuYFq+oo4CiAvfbaa6rnSpI0VMvWcq+qS9rvlwMfBvYGfjTqbm+/X96efgmw3djTt22PSZKkBSxLuCf5zSR3GN0G/hA4FzgZOKg97SDgpPb2ycBT2lnz+wBXj3XfS5Kk9ViubvmtgQ8nGb3nCVX1n0m+ApyY5BDgQuDx7fkfB/YDzgd+ARy8THVKktR7yxLuVXUBsNs8x38CPHSe4wU8exlKkyRpcLq+FE6SJC0yw12SpIEx3CVJGhjDXZKkgTHcJUkaGMNdkqSBMdwlSRoYw12SpIEx3CVJGhjDXZKkgTHcJUkaGMNdkqSBMdwlSRoYw12SpIEx3CVJGhjDXZKkgTHcJUkaGMNdkqSBMdwlSRoYw12SpIEx3CVJGhjDXZKkgTHcJUkaGMNdkqSBMdwlSRoYw12SpIEx3CVJGhjDXZKkgTHcJUkaGMNdkqSBMdwlSRoYw12SpIEx3CVJGhjDXZKkgTHcJUkaGMNdkqSBMdwlSRqYZQ33JBsnOTvJx9r7OyT5UpLzk3wgyW3a45u2989vH99+OeuUJKnPlrvlfhjw7bH7rwReW1V3A64EDmmPHwJc2R5/bXueJEmawLKFe5JtgUcA72zvB3gI8MH2lGOBx7S3H93ep338oe35kiRpAcvZcn8d8ALg5vb+bwFXVdWN7f2LgW3a29sAFwG0j1/dnr+GJIcmOTPJmVdcccVS1i5JUm8sS7gneSRweVWdtZivW1VHVdVeVbXX6tWrF/OlJUnqrVXL9D4PAP44yX7AbYHNgNcDWyRZ1bbOtwUuac+/BNgOuDjJKmBz4CfLVKskSb22LC33qvr7qtq2qrYHngh8qqr2B04DHtuedhBwUnv75PY+7eOfqqpajlolSeq7rq9z/zvguUnOpxlTP7o9fjTwW+3x5wIv7Kg+SZJ6Z7m65X+tqk4HTm9vXwDsPc851wOPW9bCJEkaiK5b7pIkaZEZ7pIkDYzhLknSwBjukiQNjOEuSdLAGO6SJA2M4S5J0sAY7pIkDYzhLknSwBjukiQNjOEuSdLAGO6SJA2M4S5J0sAY7pIkDYzhLknSwBjukiQNjOEuSdLAGO6SJA2M4S5J0sAY7pIkDYzhLknSwBjukiQNjOEuSdLAGO6SJA2M4S5J0sAY7pIkDYzhLknSwEwc7kmet47jz128ciRJ0q01Tcv9xes4/g+LUYgkSVocqxY6IclD2psbJ3kwkLGHdwSuWYrCJEnShlkw3IGj2++3Bd41dryAy4C/WuyiJEnShlsw3KtqB4Akx1XVU5a+JEmSdGtM0nIHYDzYk2w057GbF7MoSZK04aaZLb9nkjOSXAvc0H7d2H6XJEkzYuKWO3As8FHgqcAvlqYcSZJ0a00T7ncFXlRVtVTFSJKkW2+a69w/DPzhUhUiSZIWxzQt99sCH07yOZpL4H5toVn0SW4LfAbYtH3PD1bV4Ul2AN4P/BZwFnBgVf0qyabAccD/AX4CPKGqfjBFrZIkrVjThPu32q8N8UvgIVX18ySbAJ9L8gngucBrq+r9Sd4GHAK8tf1+ZVXdLckTgVcCT9jA95YkaUWZ5lK4l2zom7Tj9D9v727SfhXwEODJ7fFjgSNowv3R7W2ADwJvShLH+yVJWtjE4T62DO1aqupTEzx/Y5qu97sBbwa+B1xVVTe2p1wMbNPe3ga4qH3tG5NcTdN1/+M5r3kocCjAXe5yl0n/UyRJGrRpuuWPnnN/NXAbmlDecaEnV9VNwO5JtqCZnHePKd57Xa95FHAUwF577WWrXpIkpuuW32H8ftsS/wem3Dimqq5Kchpwf2CLJKva1vu2wCXtaZcA2wEXJ1kFbE4zsU6SJC1gmkvh1tC2xP8JeMFC5yZZ3bbYSfIbwB8A3wZOAx7bnnYQcFJ7++T2Pu3jn3K8XZKkyUzTLT+fPwAmWVf+TsCxbWt/I+DEqvpYkm8B70/yMuBsbun6Pxo4Psn5wE+BJ97KOiVJWjGmmVB3Ec0M95Hb0Vz7/qyFnltV3wD2mOf4BcDe8xy/HnjcpLVJkqRbTNNyP2DO/WuB/6mqny1iPZIk6VaaZkLdp+HX271uDfzIrV4lSZo902z5eockxwHX0cxmvy7JsUk2X7LqJEnS1KaZLf9G4DeBewO/0X6/HfCGJahLkiRtoGnG3B8O7FhVo73c/yfJwTQrzUmSpBkxTcv9eppV6cZtRbMpjCRJmhHTtNzfCZyS5DXAhcBdgecA71iKwiRJ0oaZJtz/iWYi3f7AnYEfAq+qqrlrzkuSpA5N0y3/euC8qnpYVe1aVQ8Dvp3kdUtUmyRJ2gDThPuTgDPnHDuLW/ZjlyRJM2CacC9g4znHRmvFS5KkGTFNMH8WeGm7Qt1opboj2uOSJGlGTDOh7jDgY8ClSS4E7gJcCjxqKQqTJEkbZpq15S9OsifNLm7bARcBX3Z9eUmSZstU+7m3Qf7F9kuSJM0gJ8NJkjQwhrskSQNjuEuSNDCGuyRJA2O4S5I0MIa7JEkDY7hLkjQwhrskSQNjuEuSNDCGuyRJA2O4S5I0MIa7JEkDY7hLkjQwhrskSQNjuEuSNDCGuyRJA2O4S5I0MIa7JEkDY7hLkjQwhrskSQNjuEuSNDDLEu5JtktyWpJvJflmksPa41smOSXJd9vvd2yPJ8kbkpyf5BtJ9lyOOiVJGoLlarnfCPxtVe0K7AM8O8muwAuBU6tqZ+DU9j7AvsDO7dehwFuXqU5JknpvWcK9qi6tqq+2t68Bvg1sAzwaOLY97VjgMe3tRwPHVeOLwBZJ7rQctUqS1HfLPuaeZHtgD+BLwNZVdWn70GXA1u3tbYCLxp52cXtMkiQtYFnDPcntgQ8Bf1NVPxt/rKoKqClf79AkZyY584orrljESiVJ6q9lC/ckm9AE+3ur6t/bwz8adbe33y9vj18CbDf29G3bY2uoqqOqaq+q2mv16tVLV7wkST2yXLPlAxwNfLuqXjP20MnAQe3tg4CTxo4/pZ01vw9w9Vj3vSRJWo9Vy/Q+DwAOBM5J8rX22P8DXgGcmOQQ4ELg8e1jHwf2A84HfgEcvEx1DkC6LmAeU422SJJupWUJ96r6HOtOnYfOc34Bz17SoiRJGihXqJMkaWCWq1teWtAzZmxE4e2OJkjqKVvukiQNjOEuSdLAGO6SJA2M4S5J0sAY7pIkDYzhLknSwBjukiQNjOEuSdLAGO6SJA2M4S5J0sAY7pIkDYzhLknSwBjukiQNjOEuSdLAGO6SJA2M4S5J0sAY7pIkDYzhLknSwBjukiQNjOEuSdLAGO6SJA2M4S5J0sAY7pIkDYzhLknSwBjukiQNjOEuSdLAGO6SJA2M4S5J0sAY7pIkDYzhLknSwBjukiQNjOEuSdLAGO6SJA2M4S5J0sAY7pIkDcyyhHuSdyW5PMm5Y8e2THJKku+23+/YHk+SNyQ5P8k3kuy5HDVKkjQUy9Vyfzfw8DnHXgicWlU7A6e29wH2BXZuvw4F3rpMNUqSNAjLEu5V9Rngp3MOPxo4tr19LPCYsePHVeOLwBZJ7rQcdUqSNARdjrlvXVWXtrcvA7Zub28DXDR23sXtsbUkOTTJmUnOvOKKK5auUkmSemQmJtRVVQG1Ac87qqr2qqq9Vq9evQSVSZLUP12G+49G3e3t98vb45cA242dt217TJIkTaDLcD8ZOKi9fRBw0tjxp7Sz5vcBrh7rvpckSQtYtRxvkuR9wIOArZJcDBwOvAI4MckhwIXA49vTPw7sB5wP/AI4eDlqlCRpKJYl3KvqSet46KHznFvAs5e2IkmShmsmJtRJkqTFY7hLkjQwhrskSQNjuEuSNDCGuyRJA2O4S5I0MIa7JEkDY7hLkjQwhrskSQNjuEuSNDCGuyRJA2O4S5I0MIa7JEkDY7hLkjQwhrskSQNjuEuSNDCGuyRJA7Oq6wKkvnvJS17SdQlrOfzww7suQVKHbLlLkjQwhrskSQNjuEuSNDCGuyRJA2O4S5I0MIa7JEkD46Vw0kr1rP/ouoK1veURXVcgDYItd0mSBsZwlyRpYAx3SZIGxnCXJGlgnFAnqVf+Nyd0XcJa7lJP7roEaQ223CVJGhhb7pK0DI7d4equS1jLQd/fvOsStERsuUuSNDC23CVJ6/SKs3/cdQlreeEeW3Vdwsyz5S5J0sDYcpckDc4nb96j6xLW8rCNzl6297LlLknSwMxsuCd5eJLzkpyf5IVd1yNJUl/MZLgn2Rh4M7AvsCvwpCS7dluVJEn9MJPhDuwNnF9VF1TVr4D3A4/uuCZJknohVdV1DWtJ8ljg4VX1tPb+gcD9quov55x3KHBoe3cX4LxlLXRyWwGzdz3Jwqx7eVn38upr3dDf2q17cd21qlbP90CvZ8tX1VHAUV3XsZAkZ1bVXl3XMS3rXl7Wvbz6Wjf0t3brXj6z2i1/CbDd2P1t22OSJGkBsxruXwF2TrJDktsATwRO7rgmSZJ6YSa75avqxiR/CfwXsDHwrqr6Zsdl3RozP3SwDta9vKx7efW1buhv7da9TGZyQp0kSdpws9otL0mSNpDhLknSwBjukiQNjOEuSVp0STZO8pyu69hQSXaY5NisMtwXWfsL/Z2u69hQSf4qyR27rmNafa0bIMk2Sf5vkt8ffXVd0/ok2STJXyf5YPv1V0k26bouzZaqugl4Utd13AofmufYB5e9ig00k5fC9VlV3dTuZneXqvrfruvZAFsDX0nyVeBdwH9VPy6p6GXdSV4JPAH4FnBTe7iAz3RW1MLeCmwCvKW9f2B77GmdVTShJHsBLwLuSvP3L0BV1X06LWwBSe4OPJ9b6gagqh7SWVGT+XySNwEfAK4dHayqr3ZX0voluQdwT2DzJH869tBmwG27qWp6Xgq3BJJ8BtgD+DJr/kL/cWdFTSFJgD8EDgb2Ak4Ejq6q73Va2AL6WHeS84D7VNUvu65lUkm+XlW7LXRsFrU/7+cD5wA3j45X1YWdFTWBJF8H3gacxS0fAqmqszoragJJTpvncM3yh5IkjwYeA/wxay6edg3w/qr6QieFTcmW+9L4x64LuDWqqpJcBlwG3AjcEfhgklOq6gXdVrduPa37AppWcG/CHbgpyU6jD01JdmQscGbcFVXVx9Uub6yqt3ZdxLSq6sFd1zCtqjoJOCnJ/avqjK7r2VC23JdIkrsCO1fVJ5PcDti4qq7puq6FJDkMeArNDkjvBD5SVTck2Qj4blXt1GmB69Djuj8E7AacyljAV9Vfd1bUApI8FDiG5oNJaLqKD66q+VppM6Wt/Ums/fP+986KmkCSI4DLgQ+zZt0/7aqmSSTZHDgcGM0j+TRwZFVd3V1Vk0lyW+AQmi76X3fHV9VTOytqCrbcl0CSp9NsRbslsBOwDU2X2kO7rGtCWwJ/OrebsqpuTvLIjmqaRF/rPpme7ZtQVacm2Zlmm2WA83o0rHAwcA+a3pJRt3wBMx3uwEHt9+ePHStgxw5qmca7gHOBx7f3D6T5YPin63zG7Dge+A7wR8CRwP7AtzutaAq23JdAkq8BewNfqqo92mPnVNW9u61sMkk2ppmgNj5xZ+YnB7az5bdjzbpnduLOSLs50t3bu+dV1Q1d1rOQdmb8M7mlNXY68PZZrxuaMfeq2mXhM7UYknytqnZf6NgsSnJ2Ve2R5BtVdZ/29/6zVbVP17VNwpb70vhlVf2qmd8FSVbRfMqeee2GPUcAP2LNls2szyY+kqZVdgFr1j2zE3cAkjwIOBb4AU0X93ZJDqoqZ8svjS8k2bWqvtV1IdPo8Qeq65L8blV9DiDJA4DrOq5pUqOf7VVJ7kUzl+e3O6xnKrbcl0CSVwFX0YwB/xXwLOBbVfWiTgubQJLzgftV1U+6rmUa7Szoe1fVr7quZRpJzgKeXFXntffvDryvqv5Pt5WtW89ny3+bZqjs+zRj1325FO6dNB+ojm0PHQjcVFUz/YEqyW7AccDmND/rnwJ/XlVf77SwCSR5Gs217vehGUq4PfDiqnpbp4VNyJb70nghzUSMc4BnAB+nmeTVBxcBMz/ZZR7nAlvQTDrqk01GwQ5QVf/TgwVh+jxb/uFdF7CB7jvnw9On2svjZlob4rsl2ay9/7OOS5pYVY3+Zn+a2Z/bsBbDfQlU1c3AO9qvvrkAOD3Jf7DmrNzXdFfSRF4OnJ3kXNase9bXFjizbZW9p71/AHBmh/VM4vnAaUnWmC3fbUkTWwVcXFW/bIdE7kPTspx1vfxAlWRT4M+A7YFVo6HKqjqyw7ImkmRr4J+BO1fVvkl2Be5fVUd3XNpE7JZfAu240hGsvQrWzH/6S3L4fMer6iXLXcs0knwTeDtrL07y6c6KmkD7x+/ZwO+2hz4LvGXWZ5+3dfdutnw72XUvmrD5OHAScM+q2q/LuhbS18sPk/wnTU/g3MV3Xt1ZURNK8gman/mLqmq3du7U2b2ZGG24L752bfnnsPYvdG/GsZPcHqCqft51LZNI8pWqum/XddwaSbYEtq2qb3Rdy/q01/8+i+YDSdF8IHlbVV3faWETSPLVqtozyQuA66rqjaNZ0V3XtpA+fqBKcm5V3avrOjbE6G/K+O9HX2b6g93yS+XqqvpE10VsiHZW6PE0142T5MfAU6rqm50WtrDPJnk5zTXj493yM30pXJLTaZa5XEXzYfDyJF+oqlneTes4mqU439jefzLN78zjOqtocjckeRLNZNdHtcdmdo5DkodU1afmrHEOcLckM7/4Ds3VCfeuqnO6LmQDXJvkt2ivdEqyDz2aj2S4L6Ike7Y3T0vyLzQLY/QmaFpHAc8ddfe145LvAP5vl0VNYNTyGr8GdeYvhQM2r6qftTNzj6uqw5PMdMsduFdV7Tp2/7Qkfbm07GDgL4B/qqrvp9nC8/iOa1qfBwKf4pYPIuNmdvGdJOfQ1LcKOLidn9GbqxNaz6VpLOyU5PPAauCx3ZY0ObvlF9E6NkkYmenNEkb6fJlTH7V/BP+Q5hKnF1XVV0aLZnRc2joleQ/wpqr6Ynv/fsCzq+op3VY2XEl2qKrvL3RsVrTLb6/T3JUkZ1U7zr4LzYeSmV9gapwt90U02iQhyY5VdcH4Y+3s1j64IMk/cktr5gCaSTwzrcczW48E/gv4XBvsOwLf7bimeY21xjah6W793/b+XWmW6ZxZSU6sqseP/TesYZY/TLU+BOw559gHgZlcD2E8vNsezdH8jM/3pAdz3rklSXoxtwRsuS+J0aSdOcfOmuWFSUbaJVxfwpqzt4+oqiu7q2phfZ/Z2gd9bo0luVNVXbqu/4ZZrT237C3+KtZcV34z4PlVdc9OCptQkhfTzMUYDR88Bvi3qnpZd1VNJsmJNHNLRpepPhnYoqr6MLfElvtiGvuHuPmcCTCbMbar0CxrQ3xmdyRbj62q6sQkfw9QVTcmmdnrgJO8oKpeleSNzN+SnLn/B3MDMMlv05/f60vb7zMZ4uuxC/BImgWaxsfdrwGe3klF09kf2G3U2k3yCuBrwMyHO/2eW2K4L7K+/0McLX/6PNpFJ0bHezBfoG8zW0e7S836gjVrSfLHwKuBO9OsCHhXmv+emW5FArQful9Js0Z4uGWC12adFrYO1f+9xX9I8wFw1JW9KXBJd+VM5atJ9pkzt6Q3/17tll8CPf6HSLuk5dtY+xr9szoragLtuN4bgXvRLEW7GnjsLF8znmb3vVdW1fO6rmUa7e/IQ4BPVrNr1oOBA6rqkI5LW1CavRMeVVW92Lqzjz0845J8BLgvcApN/X8AfBm4GGa7/nYfgl2A0Y6YdwHOA26kBzP+bbkvjYuSfBh4QHv/s8BhVXVxhzVN6saqemvXRUyrqr6a5IH0aGZrVd3UrmbYNzdU1U+SbJRko6o6Lcnrui5qQj/qS7C3etvD0/pw+zVyekd1bIi+7kMA2HJfEklOAU5gzRnn+1fVH3RX1fq1q6NBM95+Oc0/yPFr9H/aRV2TSvI44D+r6pok/0Azs/hlsz4zN8lbgW2AfwOuHR2f5cVJknySZmLUy4GtaH5f9qqqmf2gMjYH5oHA7wAfYc3f75n9ec+VZCPg9tWjTVj6KsnvAjtX1TFJtgLuMKuXH85luC+BdVwrPtPLFib5Pk23WeZ5eObXxR9dG97+Y3wp8K802zPer+PS1ivJMfMcrqp66rIXM6Ekr6aZub0RzYSpzWkmTc1st/w6fs4jM/3zBkhyAs3iOzcBX6GZpPv6qvqXTgtbQJKdaT4E7srY5MtZ/3sCv95nYy9gl6q6e5I708z0n9kPsePsll8aP05yAPC+9v6TgJleV76qdui6hltpND/gEcA7quo/ksz8jNyq6stuauMeXM3OhzfT7i8+66vq9fTnPG7XdiXD/YFP0GwrfRYw0+FOc3nq4cBrgQfTrBC4UacVTe5PaFa+/CpAVf0wyR26LWlyhvvSeCrN5K7X0rSGv0BPtsTs8aYglyR5O82EnVe2m2zM/B+R9ud9CM1M8/GWzcy1JJM8k+Z3Y6c5YX4H4PPdVDWddpGg19MsU1zAGcDf9KCrdZMkm9AMh7ypqm5I0odu19+oqlOTpL0M8YgkZwEv7rqwCfyqqmr0c07ym10XNA3DfQm0v8Szvo/4uvR1U5DH00yA+dequirJnVhz0Y9ZdTzN6m5/RLNa3f7cMolq1pxA02p8OU3LceSaWZ+TMeYE4OFLPWoAAA32SURBVM00rTKAJwLvB2Z6+IZmO+MfAF8HPtMuxtOHMfdftnMEvpvkL2kug7t9xzUtKEmAj7UNhi2SPJ2m0faObiubnGPuSyDJaprr2rdnzWvFZ641NleSb81ZuGHeY7OmHQd+V83+7nVrSLud5NicgU2Az1bVPgs+WVObb93+vu6dkGRVVd3YdR3rk+S+NB9Wt6CZC7MZ8Kqq+lKnhU2gXar4uTR7PwT4r6o6pduqJmfLfWmcRNOd/UnGrhXvib4u3PBt4Kh22dljgPdV1SwvYjMyulzvqjTb7V5Gs8CKlsYnkryQprVewBOAj4+uFpnVHogkm9OMXf9+e+jTND09s/47vn1VfQX4Oe3QZHtly8yHO81Y+1VV1YcewLXYcl8Csz4zfn36vnBDkl1o/og8iWYc+B3Vbl87i9Js9foh4D40H0puD/xjVb2908IGqr0qZF1m9qqQJB+iWZzp2PbQgTRXKMzd532mrGOfjbWOzaIk3wHuBlzImpepzvTfwBHDfQm0s7S/UFUf77qWafV8c5CNaZb/PRjYDjiRZmLgtVX1xC5rU/fasd/7V1UvJv+Nm6/BMMuNiCT7AvvRzIX5wNhDm9HM/N+7k8Km0LdNhuYy3JdAkmuA36RZJOMGZnz96rmS7Ab8Xnv3s1X19S7rmUSS19Ks538qcHRVfXnssfOqapfOiluPdj38I2hWMxxdnfDSqprpSyf7ajTHoes6ppXkDJpd4D7X3n8AzeTR+3db2fzavyG70wwdjM+MvwY4rWZ8l8khMNyXSDuGtzNrXt706e4qmkySw2gmA45W7PoT4KiqeuO6n9W9JAcDJ1bVtfM8tvmsjr+3qxl+hlu2ldwfeFBVPay7qoYryb/SXP7279WjP35Jdqfpkt+cprHwU+CgWd47AaCdILoKuEtVndd1PSuJ4b4E2nHUw4BtabY33Iemm/6hnRY2gfb65fuPQrK9tvOMWR1najeMWaceLD97blXda86xc8p96JfEWK/aTcB19K9XbTOAviw9m+RRNKtF3qaqdmg/pBxZVX29VLg3nC2/NA6j2Qnpi1X14DT7vP9zxzVNKqw5w/8m5l+Sdla8ej2PFc3uZbPsv5M8kWZ+AMBjgf/qsJ5Bq6rerDA2rh2+OZx2cakkn6MJyVkfvjkC2Jt2w5iq+lqSvq+G2QuG+9K4vqquT0KSTavqO+0s7j44BvhSml3toFkR6+gO61mvqnpw1zXcSk8H/oZbuuU3otmb/hn0qEXZJ2n2ox9dUnZ6VX2sy3om9H6a4Zs/a+/vTzNRbdaHb26oqqubNWF+ze7iZWC4L42Lk2xBs/PUKUmupLmcYuZV1WuSnE7TQgA4uKrO7rCkibRje89k7I828Paa/W1fe9mS7Kskr6DpVXtve+iwJA+oqr/vsKxJ3KmqXjp2/2VJntBZNZP7ZpInAxu3m8j8Nc1y3FpijrkvsTR7jG9Osx3pr7quZxJJ7khzKdn46nqzPnb9TmAT1rwO+Kaqelp3VU0myX1YezXD3mxB2iftnJLd241vRpdPnj2rc0pGkrwG+DJrDt/sXVXP666qhSW5HfAimlXeoBlyemlV/XLdz9JiMNy1hiQvBf4c+B63dJ9VVc302PV8S4j2YVnRJO+iWcDmmzS7rEEPtiDtqzbcHzRaia69quX0HoT7aCLg6HdkI25ZWGVmh2+S7EUT7ttzy4fXmV8Mawjsltdcjwd26ksvw5ibkuxUVd+DX+/+1Yelf/eZ9XX7B+blwNlJTqOZKPr7rLkJzkzq8fDNe4Hn0ayud/MC52oRGe6a61yaTR4u77qQKT0fOC3JBe397enHNrtnJNm1qr7VdSErQVW9r51Tct/20N9V1WUdljSxng7fXFFVH+26iJXIbnmtoe1GO4km5H89Ljbr16Wm2Rf9b4GHAlcBXwFeWzO+D307J+Nkmg1jfskt113bbblE+hiSfR2+SfJQmn0eTmXNvycz/fMeAsNda0jyTZq9o89hrBtt1lfXS3Iizf7Wo1nQTwa2qKqZ3oc+yfk020rO/Xn34uqKvulxSM78tsvzSfIe4B707Oc9BHbLa65fVNUbui5iA9xrzh+/05L0oav7iqo6uesiVpC+znHo6/DNfWd1X4ehM9w112eTvJymq3i8G22mL4Wjv/vQn53kBOCj2G25HPoaksfR1N634Zsv9PTn3Xt2y2sN7SziufpwKVwv96FPcsw8h+22XCJ9nePQ1+Gb9t/lTsD36dHPewgMdw1Cn/eh1/LpcUieMavbu65P3/dE7zPDXWtIsjnNBhWjZVw/TbNBxUxumdp3SbYF3kiznzs0+7kfVlUXd1fVcPU4JN9Cc4mqwzeaiOGuNST5EM1lcOPLuO5WVX/aXVXD1e7nfgJwfHvoAGD/qvqD7qoarr6GpMM3mpbhrjUk+VpV7b7QMS0Of97Ly5DUSuFsec11XZLfrarPASR5AHBdxzUN2U+SHAC8r73/JGDW9+jurarqw6qFa3H4RtPaqOsCNHOeCbw5yQ+S/AB4E/CMbksatKfSrOd/GXApzW5ff95lQUOWZNskH05yefv1oTY4Z90xNLP879x+fbQ9Js3LbnmtIcmmNAGzE83Y5NU03ZZHdlrYQCU5Fvibqrqyvb8l8K92Ey+Nvs5xcPhG07LlrrlOAh4FXA9cAvycW7aW1OK7zyjYAdqtSPfosJ6hW11Vx1TVje3Xu4HVXRc1gZ8kOSDJxu3XATh8o/VwzF1zbVtVD++6iBVkoyR3nNNy99/l0unrHIen0oy5vxYo4As4fKP18I+I5vpCkntX1TldF7JCvJpmWdF/a+8/DvinDusZuvGQBPg8/dga+EjgoLnDNzT/PdJaHHMXAEnOoWkRrAJ2Bi7A5SKXRZJdgdHyvp9yHW7NleTsqtpjoWPSiC13jTyy6wJWqjbMDfRlkGRH4PXAPjQfZs8AnlNVF3Ra2MIcvtFU/OUQ4FrPWjFOAN4M/El7/4k04+/366yiyTh8o6nYLS9pxUjyjblDTEm+XlW7dVXTpBy+0TQMd0krRpJXAlcC76fpln8CcEfgX+DXlyJKvWe4S1oxknx/PQ9XVe24bMVIS8hwlyRpYJxQJ2nFSLIJzf4Jv98eOh14e1Xd0FlR0hKw5S5pxUjyTmAT4Nj20IHATVX1tO6qkhaf4S5pxZhvZnxfZstL03DjGEkryU1JdhrdaRe1uanDeqQl4Zi7pJXkecBpSS6gWVr5rvRjbXlpKoa7pBUhycbAbjR7J+zSHj6vqn7ZXVXS0nDMXdKKkeTLVbV313VIS81wl7RiJHktzWz5DwDXjo5X1Vc7K0paAoa7pBUjyWnzHK6qesg8x6XeMtwlrRhJdpy7vet8x6S+81I4SSvJB+c59m/zHJN6zdnykgYvyT2AewKbJ/nTsYc2A27bTVXS0jHcJa0EuwCPBLYAHjV2/Brg6Z1UJC0hx9wlrRhJ7l9VZ3Rdh7TUDHdJK0aS1TQt9e0Z67msqqd2VZO0FOyWl7SSnAR8FvgkrimvAbPlLmnFSPK1qtq96zqkpealcJJWko8l2a/rIqSlZstd0oqR5BrgN4FfAjfQ7AxXVbVZp4VJi8wxd0krRlXdIcmWNDvDeX27Bstwl7RiJHkacBiwLfA1YB/gC8BDu6xLWmyOuUtaSQ4D7gtcWFUPBvYAru62JGnxGe6SVpLrq+p6gCSbVtV3aFavkwbFbnlJK8nFSbYAPgKckuRK4MKOa5IWnbPlJa1ISR4IbA78Z1X9qut6pMVkuEuSNDCOuUuSNDCGuyRJA2O4SwOU5AdJHtZ1HXMl2T5JJXEyr7SEDHdJkgbGcJckaWAMd2nAkuyd5IwkVyW5NMmbktxm7PFK8hdJvtue8+YkaR/bOMmrk/w4yfeT/OUkXepJTk/y8iRfTvKzJCe167nPd+7BSb6d5JokFyR5xthj5yZ51Nj9Tdpa9rj1Pxlp2Ax3adhuAp4DbAXcn2YN9WfNOeeRNEuy3gd4PPBH7fGnA/sCuwN7Ao+Z4n2fAjwVuBNwI/CGdZx3efv+mwEHA69Nsmf72HHAAWPn7gdcWlVnT1GHtCIZ7tKAVdVZVfXFqrqxqn4AvB144JzTXlFVV1XV/wKn0YQ5NEH/+qq6uKquBF4xxVsfX1XnVtW1wD8Cj0+y8Tz1/UdVfa8anwb+G/i99uH3APslGW3HeiBw/BQ1SCuW4S4NWJK7J/lYksuS/Az4Z5pW/LjLxm7/Arh9e/vOwEVjj43fXsj4uRcCm8zzviTZN8kXk/w0yVU0rfOtAKrqh8DngT9rl4zdF3jvFDVIK5bhLg3bW4HvADtX1WbA/wMy4XMvpdkadWS7Kd53/Ny7ADcAPx4/IcmmwIeAfwW2rqotgI/Pqe9Ymq75xwFnVNUlU9QgrViGuzRsdwB+Bvw8yT2AZ07x3BOBw5Js07ac/26K5x6QZNcktwOOBD5YVTfNOec2wKbAFcCNSfYF/nDOOR+hGe8/jGYMXtIEDHdp2J4HPBm4BngH8IEpnvsOmjHwbwBn07Sqb6SZpLeQ44F303T53xb467knVNU17fETgSvbOk+ec851NK37HYB/n6J2aUVz4xhJE2lb1m+rqrsucN7pwHuq6p2L9L4vBu5eVQcseLIkwJa7pHVI8htJ9kuyKsk2wOHAh5e5hi2BQ4CjlvN9pb4z3CWtS4CX0HSZnw18G3gxQJKfr+Pr99bzetO9efJ0mln3n6iqzyzW60orgd3ykiQNjC13SZIGxnCXJGlgDHdJkgbGcJckaWAMd0mSBub/BziFhowaK2KxAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Number of unique text_structure_labels: 9\n",
            "Number of training sentences: 1,099\n",
            "\n",
            "another            565\n",
            "homophony          192\n",
            "polysemy           185\n",
            "comparison          50\n",
            "taboo               35\n",
            "antropomorphism     24\n",
            "composition         21\n",
            "metaphor            15\n",
            "repeat              12\n",
            "Name: lang_play, dtype: int64\n",
            "Index(['joke', 'another', 'antropomorphism', 'comparison', 'composition',\n",
            "       'homophony', 'metaphor', 'polysemy', 'repeat', 'taboo'],\n",
            "      dtype='object', name='lang_play')\n",
            "{'another': 1, 'antropomorphism': 2, 'comparison': 3, 'composition': 4, 'homophony': 5, 'metaphor': 6, 'polysemy': 7, 'repeat': 8, 'taboo': 9}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MXjI6VQrycLf",
        "outputId": "2e7bd2e7-da65-43ac-d771-1fbcbd76d1d9"
      },
      "source": [
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "\n",
        "if torch.cuda.is_available():      \n",
        "    device = torch.device(\"cuda\")\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n",
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla K80\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1hPMil50wuZ"
      },
      "source": [
        "\n",
        "def train_test_split_data(df, test_size):\n",
        "  train, test = train_test_split(df, random_state=42, test_size=None, shuffle=True)\n",
        "  #skf = StratifiedKFold(n_splits=2, random_state=42)\n",
        "  #train, test = skf.split(df.joke, df.labels)\n",
        "  return train, test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182,
          "referenced_widgets": [
            "82e27432fbb14f649946ecd8386a3c50",
            "f4581629514947ce98c78ea8d5b278ca",
            "d88e563bce5343a4bfe553c4edf9b550",
            "303580dc4c4846a3aff6f205fad7d0e7",
            "b3a9c5f5ec644398b52521ce59a84c37",
            "e1a6f3b0864e4b3db67cc3b68a2aa94e",
            "5974960d13424621b0563f9a098065db",
            "faf35afb7adc4df5b784b293731118d7",
            "c8fd398bb0f147e68ce79ca6f9987b1e",
            "0181c89d812b4b6aa95d7fe2ef22ba9c",
            "5d73ddb300604959b0526b7adb47e176",
            "8026111ae512457aa3a7d663424b5711",
            "0eac4e5259d04a6eb4c430130498b35a",
            "18463760a8ac47c3b55e5f437ca29e1d",
            "a9504ca4e1784f86b1d2282d961ad024",
            "0346fc00b15b4ebeb9dab416f0ee67a7",
            "e7ca593edd1b4d23ac875b912a6e38cf",
            "8269262e3c7b4a8687c1900e218fe827",
            "65d82e116fc04ee6b35c0e3c0283f497",
            "1e509a1e590047689246540bee1fa049",
            "aa27beb689b54ebcb19f25b631d7a29d",
            "1cc7cf61263b4936b2e1abfe2b1f9af4",
            "76d1c539b0954a088ec958d4d20a122a",
            "f5f405a5c2da4695aca22c12f5551bff"
          ]
        },
        "id": "onga2sW42MFT",
        "outputId": "881e766d-845a-4503-9362-ef227c00fb35"
      },
      "source": [
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-cased\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading BERT tokenizer...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "82e27432fbb14f649946ecd8386a3c50",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=213450.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c8fd398bb0f147e68ce79ca6f9987b1e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=29.0, style=ProgressStyle(description_w…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e7ca593edd1b4d23ac875b912a6e38cf",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=435797.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9CFYQGb2khc"
      },
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "def prepare_data(sentences,tokenizer):\n",
        "  input_ids = []\n",
        "  attention_masks = []\n",
        "\n",
        "  # For every sentence...\n",
        "  for sent in tqdm(sentences, total=len(sentences)):\n",
        "      # `encode_plus` will:\n",
        "      #   (1) Tokenize the sentence.\n",
        "      #   (2) Prepend the `[CLS]` token to the start.\n",
        "      #   (3) Append the `[SEP]` token to the end.\n",
        "      #   (4) Map tokens to their IDs.\n",
        "      #   (5) Pad or truncate the sentence to `max_length`\n",
        "      #   (6) Create attention masks for [PAD] tokens.\n",
        "      encoded_dict = tokenizer.encode_plus(\n",
        "                          sent,                      # Sentence to encode.\n",
        "                          add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                          max_length = 512,           # Pad & truncate all sentences.\n",
        "                          pad_to_max_length = True,\n",
        "                          return_attention_mask = True,   # Construct attn. masks.\n",
        "                          return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                    )\n",
        "      \n",
        "      # Add the encoded sentence to the list.    \n",
        "      input_ids.append(encoded_dict['input_ids'])\n",
        "      \n",
        "      # And its attention mask (simply differentiates padding from non-padding).\n",
        "      attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "  # Convert the lists into tensors.\n",
        "  input_ids = torch.cat(input_ids, dim=0)\n",
        "  attention_masks = torch.cat(attention_masks, dim=0)\n",
        "  #labels = torch.tensor(labels)\n",
        "\n",
        "  return input_ids, attention_masks"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlXxhfQReuqa"
      },
      "source": [
        "def format_time(\n",
        "    elapsed\n",
        "):\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lpCrTBxTQ5uR"
      },
      "source": [
        "def eval_result(target, predict):\n",
        "  print('Test Accuracy is {}'.format(accuracy_score(target, predict)))\n",
        "  print('Test F1 is {}'.format(f1_score(target, predict, average='weighted')))\n",
        "  print('Test Precision is {}'.format(precision_score(target, predict, average= 'weighted')))\n",
        "  print('Test Recall is {}'.format(recall_score(target, predict, average='weighted')))\n",
        "  #print('Test for all classes {}').format(classification_report(target, predict, target_names=[0, 1, 2]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cy5jQ63csHEc"
      },
      "source": [
        "class BertForSequenceClassification(BertPreTrainedModel):\n",
        "    def __init__(self, config, num_classes):\n",
        "        super().__init__(config)\n",
        "        self.config = config\n",
        "\n",
        "        self.bert = BertModel(config)\n",
        "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "        self.classifier = nn.Linear(config.hidden_size, num_classes)\n",
        "\n",
        "        self.init_weights()\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        input_ids=None,\n",
        "        attention_mask=None,\n",
        "        token_type_ids=None,\n",
        "        position_ids=None,\n",
        "        head_mask=None,\n",
        "        inputs_embeds=None,\n",
        "        labels=None,\n",
        "        output_attentions=None,\n",
        "        output_hidden_states=None,\n",
        "        return_dict=None,\n",
        "    ):\n",
        "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
        "\n",
        "        outputs = self.bert(\n",
        "            input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            token_type_ids=token_type_ids,\n",
        "            position_ids=position_ids,\n",
        "            head_mask=head_mask,\n",
        "            inputs_embeds=inputs_embeds,\n",
        "            output_attentions=output_attentions,\n",
        "            output_hidden_states=output_hidden_states,\n",
        "            return_dict=return_dict,\n",
        "        )\n",
        "\n",
        "        pooled_output = outputs[1]\n",
        "\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "        logits = self.classifier(pooled_output)\n",
        "\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "            loss_fct = BCEWithLogitsLoss()\n",
        "            loss = loss_fct(logits, labels)\n",
        "\n",
        "        if not return_dict:\n",
        "            output = (logits,) + outputs[2:]\n",
        "            return ((loss,) + output) if loss is not None else output\n",
        "\n",
        "        return SequenceClassifierOutput(\n",
        "            loss=loss,\n",
        "            logits=logits,\n",
        "            hidden_states=outputs.hidden_states,\n",
        "            attentions=outputs.attentions,\n",
        "        )\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FlyVTQM-L3Lw",
        "outputId": "e1719041-879f-4180-e4f5-829823252f2f"
      },
      "source": [
        "# prepare input: cut and pad\n",
        "\n",
        "train, test = train_test_split_data(df, test_size=0.33)\n",
        "#test, val = train_test_split_data(test_val, test_size=0.5)\n",
        "train_joke = train.joke\n",
        "test_joke = test.joke\n",
        "train_input_ids, train_attention_masks = prepare_data(sentences = train_joke, tokenizer=tokenizer)\n",
        "test_input_ids, test_attention_masks = prepare_data(sentences= test_joke, tokenizer=tokenizer)\n",
        "#val_input_ids, val_attention_masks\n",
        "train.shape\n",
        "#input_ids, attention_masks, labels = prepare_data(sentences= df[\"joke\"], labels=df[\"lang_play_two\"], tokenizer=tokenizer)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/399 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "100%|██████████| 399/399 [00:00<00:00, 936.99it/s]\n",
            "100%|██████████| 134/134 [00:00<00:00, 1014.12it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(399, 9)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pp97L1Tlf54B"
      },
      "source": [
        "def prepare_dataloader_train(train, train_input_ids, train_attention_masks, labels, batch_size):\n",
        "  train_inputs = torch.tensor(train_input_ids)\n",
        "  train_masks = torch.tensor(train_attention_masks)\n",
        "  train_labels = torch.tensor(train[labels].to_numpy(), dtype = torch.float)\n",
        "  train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "  dataloader_train = DataLoader(train_data, \n",
        "                                sampler=RandomSampler(train_data), \n",
        "                                batch_size=batch_size)\n",
        "  return dataloader_train\n",
        "\n",
        "def prepare_dataloader_validation(test, test_input_ids, test_attention_masks, labels, batch_size):\n",
        "  test_inputs = torch.tensor(test_input_ids)\n",
        "  test_masks = torch.tensor(test_attention_masks)\n",
        "  test_labels = torch.tensor(test[labels].to_numpy(), dtype = torch.float)\n",
        "  test_data = TensorDataset(test_inputs, test_masks, test_labels)\n",
        "  dataloader_val = DataLoader(test_data, \n",
        "                              sampler=SequentialSampler(test_data), \n",
        "                              batch_size=batch_size)\n",
        "  return dataloader_val"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECM09kzGwnZz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e232743-fd81-48ec-8723-c13268d4d54e"
      },
      "source": [
        "dataloader_train = prepare_dataloader_train(\n",
        "    train = train, train_input_ids=train_input_ids, train_attention_masks=train_attention_masks, labels=categories, batch_size=12)\n",
        "dataloader_val = prepare_dataloader_validation(\n",
        "    test=test, test_input_ids=test_input_ids, test_attention_masks=test_attention_masks,  labels=categories, batch_size=12)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  if sys.path[0] == '':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223,
          "referenced_widgets": [
            "f6c2a58c9dab4cc692b67d30174ba344",
            "7b0adbeecabb43539b3db148d8207fd4",
            "81d7c56bac0a4ce4ad249e68e7d591c7",
            "16fd439295684b5ab8e4631e673a8b59",
            "fc4d19e99f584adcb3e7d73c407a33a6",
            "18c9a355f7c840c6bf0316effc5254d4",
            "fd8b70d281c5471fa2cf38bb33f4f4b3",
            "e7c983d515554b57bd42b2c00a919664",
            "36570ecb94e540d0a4494bdbaac6447f",
            "69df13e118f14807a425dd5fa843f389",
            "27c27409d3ce43e697c0a1d38ec2a09c",
            "290fdda386104df2b4a6ce0aecea31bb",
            "b22ca5d1c0384b13b1d44dc5108c2bf6",
            "60f6b260199546dca4dcbad5ffb1d682",
            "cf54e57017dd434d81a2600e2d2e639b",
            "5a9b245496824420b5c18b0355ae46f6"
          ]
        },
        "id": "kuH3YHIQKHEF",
        "outputId": "5816405e-5cfb-4749-eb5e-3e0aa0a3d1b8"
      },
      "source": [
        "batch_size=32\n",
        "epochs=5 #1\n",
        "seed_val=42\n",
        "device = device\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "#torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "        \"bert-base-cased\",\n",
        "        output_attentions=False,\n",
        "        output_hidden_states=True,\n",
        "        num_classes=len(categories)\n",
        "    )\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "optimizer = AdamW(\n",
        "    model.parameters(),\n",
        "    lr=2e-5, \n",
        "    eps=1e-8\n",
        ")\n",
        "\n",
        "total_steps = len(dataloader_train) * epochs\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer, \n",
        "    num_warmup_steps=50, # Default value in run_glue.py\n",
        "    num_training_steps=total_steps\n",
        ")\n",
        "\n",
        "loss_train, loss_valid = [], []"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f6c2a58c9dab4cc692b67d30174ba344",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=570.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "36570ecb94e540d0a4494bdbaac6447f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=435779157.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ByZk1c_Xae_s"
      },
      "source": [
        "#val_loss, predictions, true_vals = evaluate(dataloader_val)\n",
        "def evaluate(dataloader_val):\n",
        "    t0 = time.time()\n",
        "    test_targets, test_pred_class = [], []\n",
        "    model.eval()\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "    valid_loss = 0\n",
        "    for batch in dataloader_val:\n",
        "        batch = tuple(b.to(device) for b in batch)\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        with torch.no_grad():        \n",
        "          outputs = model(\n",
        "              b_input_ids,\n",
        "              token_type_ids=None,\n",
        "              attention_mask=b_input_mask,\n",
        "              labels=b_labels\n",
        "          )\n",
        "        loss, logits = outputs[:2]\n",
        "        valid_loss += loss.item()\n",
        "        loss_valid.append(loss)\n",
        "\n",
        "        logits = logits.detach()\n",
        "        probs = nn.Sigmoid()(logits).cpu().numpy()\n",
        "        label_ids = b_labels.detach().cpu().numpy()\n",
        "        classes = np.where(probs > 0.5, 1., 0.)\n",
        "        test_pred_class.append(label_ids)\n",
        "        test_targets.append(classes)\n",
        "        nb_eval_steps += 1\n",
        "    avg_valid_loss = valid_loss/len(dataloader_val) \n",
        "    \n",
        "    test_pred_class = np.concatenate(test_pred_class, axis=0)\n",
        "    test_targets = np.concatenate(test_targets, axis=0)\n",
        "            \n",
        "    return avg_valid_loss, loss_valid, test_pred_class, test_targets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "id": "p6yHdNELEZVv",
        "outputId": "0a9847e9-9dcc-4e7c-d442-cb00a75c4b6d"
      },
      "source": [
        "for epoch_i in range(0, epochs):\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i, epochs))\n",
        "    print('Training...')\n",
        "    total_loss = 0\n",
        "    model.train()\n",
        "    with tqdm(dataloader_train, total=len(dataloader_train), unit=\"batch\") as tepoch:\n",
        "        for batch in tepoch:\n",
        "            tepoch.set_description(f\"Epoch {epoch_i}\")\n",
        "            b_input_ids = batch[0].to(device)\n",
        "            b_input_mask = batch[1].to(device)\n",
        "            b_labels = batch[2].to(device)\n",
        "            model.zero_grad()\n",
        "            outputs = model(\n",
        "                b_input_ids,\n",
        "                token_type_ids=None,\n",
        "                attention_mask=b_input_mask,\n",
        "                labels=b_labels\n",
        "            )\n",
        "            loss = outputs[0]\n",
        "            total_loss += loss.item()\n",
        "            loss.backward()\n",
        "            loss_train.append(loss.item())\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "            tepoch.set_postfix(loss=loss.item())\n",
        "    avg_valid_loss, loss_valid, test_pred_class, test_targets = evaluate(dataloader_val)\n",
        "        \n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average valid loss: {0:.2f}\".format(avg_valid_loss))\n",
        "\n",
        "    eval_result(test_targets.squeeze().flatten(), test_pred_class.squeeze().flatten())\n",
        "\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Training complete!\")\n",
        "    \n",
        "    plt.plot(loss_train)\n",
        "    plt.title('Train loss')\n",
        "    plt.show()\n",
        "    \n",
        "    plt.plot(loss_valid)\n",
        "    plt.title('Valid loss')\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0:   0%|          | 0/34 [00:00<?, ?batch/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 0 / 5 ========\n",
            "Training...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0:   3%|▎         | 1/34 [00:02<01:19,  2.40s/batch, loss=0.777]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-44c635cae79c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m                 \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                 \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mb_input_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m                 \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mb_labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m             )\n\u001b[1;32m     20\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-b9373286a646>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         )\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    979\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 981\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    982\u001b[0m         )\n\u001b[1;32m    983\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    573\u001b[0m                     \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m                     \u001b[0mpast_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 575\u001b[0;31m                     \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m                 )\n\u001b[1;32m    577\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    459\u001b[0m             \u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 461\u001b[0;31m             \u001b[0mpast_key_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself_attn_past_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    462\u001b[0m         )\n\u001b[1;32m    463\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself_attention_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    392\u001b[0m             \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m             \u001b[0mpast_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m         )\n\u001b[1;32m    396\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0;31m# This is actually dropping out entire tokens to attend to, which might\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0;31m# seem a bit unusual, but is taken from the original Transformer paper.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m         \u001b[0mattention_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_probs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0;31m# Mask heads if we want to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/dropout.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mdropout\u001b[0;34m(input, p, training, inplace)\u001b[0m\n\u001b[1;32m   1074\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0.0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1075\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dropout probability has to be between 0 and 1, \"\u001b[0m \u001b[0;34m\"but got {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1076\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1077\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1078\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 36.00 MiB (GPU 0; 11.17 GiB total capacity; 10.61 GiB already allocated; 29.81 MiB free; 10.65 GiB reserved in total by PyTorch)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GfcB_kcjABeM"
      },
      "source": [
        "#####Roc-auc\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "fpr = dict()\n",
        "tpr = dict()\n",
        "roc_auc = dict()\n",
        "num_labels=len(categories)\n",
        "\n",
        "for i in range(0, num_labels):\n",
        "    fpr[i], tpr[i], _ = roc_curve(test_targets[:, i], test_pred_class[:, i])\n",
        "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "    \n",
        "# Compute micro-average ROC curve and ROC area\n",
        "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(test_targets.ravel(), test_pred_class.ravel())\n",
        "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
        "\n",
        "result = {'roc_auc': roc_auc}\n",
        "print(result)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yib5ZlL0zIDI"
      },
      "source": [
        "list(label_dict.values())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8O6bIvIo5N7"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import multilabel_confusion_matrix, classification_report,ConfusionMatrixDisplay, confusion_matrix\n",
        "cm=multilabel_confusion_matrix(test_targets, test_pred_class)\n",
        "print(cm)\n",
        "f, axes = plt.subplots(1, len(categories), figsize=(25, 5))\n",
        "labels= list(label_dict.values())\n",
        "axes = axes.ravel()\n",
        "for i, category in enumerate(categories):\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix(test_targets[:, i],\n",
        "                                                   test_pred_class[:, i]),\n",
        "                                  display_labels=[0,1])\n",
        "    disp.plot(ax=axes[i], values_format='.4g')\n",
        "    disp.ax_.set_title(f'class {category}')\n",
        "    if i<8:\n",
        "        disp.ax_.set_xlabel('')\n",
        "    if i%8!=0:\n",
        "        disp.ax_.set_ylabel('')\n",
        "    disp.im_.colorbar.remove()\n",
        "\n",
        "plt.subplots_adjust(wspace=0.5, hspace=0.1)\n",
        "f.colorbar(disp.im_, ax=axes)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SAbfrlJVIzDE"
      },
      "source": [
        "\n",
        "#torch.save(model.state_dict(), \"./saved_model/finetuned_BERT_epoch_1\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7klAc32Hs7Vk"
      },
      "source": [
        "#########Log-regression\n",
        "\n",
        "\n",
        "#train, test = train_test_split(df, random_state=42, test_size=0.33, shuffle=True)\n",
        "train_set = train.joke\n",
        "test_set = test.joke\n",
        "\n",
        "\n",
        "LogReg_pipeline = Pipeline([\n",
        "                ('tfidf', TfidfVectorizer(stop_words=stop_words)),\n",
        "                ('clf', OneVsRestClassifier(LogisticRegression(solver='sag'), n_jobs=3)),\n",
        "            ])\n",
        "all_predictions = []\n",
        "all_targets = []\n",
        "for category in categories:\n",
        "    print('... Processing {}'.format(category))\n",
        "    # train the model using X_dtm & y\n",
        "    LogReg_pipeline.fit(train_set, train[category])\n",
        "    # compute the testing accuracy\n",
        "    prediction = LogReg_pipeline.predict(test_set)\n",
        "    eval_result(test[category], prediction)\n",
        "    all_predictions.append(prediction) \n",
        "    all_targets.append(test[category])\n",
        "print(\"... Overall metrics\")\n",
        "eval_result(\n",
        "    [value for pred_col in all_predictions for value in pred_col], \n",
        "    [value for pred_col in all_targets for value in pred_col]\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unSwmY7Qsvh0"
      },
      "source": [
        "train_set = train.joke\n",
        "test_set = test.joke\n",
        "f, axes = plt.subplots(1, len(categories), figsize=(25, 5))\n",
        "labels= list(label_dict.values())\n",
        "axes = axes.ravel()\n",
        "\n",
        "LogReg_pipeline = Pipeline([\n",
        "                ('tfidf', TfidfVectorizer(stop_words=stop_words)),\n",
        "                ('clf', OneVsRestClassifier(LogisticRegression(solver='sag'), n_jobs=3)),\n",
        "            ])\n",
        "all_predictions = []\n",
        "all_targets = []\n",
        "for i, category in enumerate(categories):\n",
        "    print('... Processing {}'.format(category))\n",
        "    # train the model using X_dtm & y\n",
        "    LogReg_pipeline.fit(train_set, train[category])\n",
        "    # compute the testing accuracy\n",
        "    prediction = LogReg_pipeline.predict(test_set)\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix(test[category],\n",
        "                                                   prediction),\n",
        "                                  display_labels=[0,1])\n",
        "    disp.plot(ax=axes[i], values_format='.4g')\n",
        "    disp.ax_.set_title(f'class {category}')\n",
        "    if i<8:\n",
        "        disp.ax_.set_xlabel('')\n",
        "    if i%8!=0:\n",
        "        disp.ax_.set_ylabel('')\n",
        "    disp.im_.colorbar.remove()\n",
        "plt.subplots_adjust(wspace=0.5, hspace=0.1)\n",
        "f.colorbar(disp.im_, ax=axes)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cH6YVl7Iaijc",
        "outputId": "ba47a1e7-4dac-4fca-879c-050f9aabe55b"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}